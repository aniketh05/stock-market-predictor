{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f2d213c",
   "metadata": {},
   "source": [
    "### Stock Price Prediction using Stacked LSTM\n",
    "\n",
    "#### 1) We will collect the stocks data - AAPL\n",
    "#### 2) Preprocess the data - Train & Test\n",
    "#### 3) Create an Stacked LSTM model\n",
    "#### 4) Predict the test data and plot the output\n",
    "#### 5) Predict the Future 30 days and plot the output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2396ebf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collection\n",
    "\n",
    "import pandas_datareader as pdr\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b70552-c28d-4bd0-bab5-90f9ed0346ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching Apple stocks data using API\n",
    "\n",
    "import requests\n",
    "headers = {\n",
    "    'Content-Type': 'application/json'\n",
    "}\n",
    "response = requests.get(\"https://api.tiingo.com/tiingo/daily/aapl/prices?startDate=2015-1-1&endDate=2024-1-1&token=b1ab3b096f8156cc006b0c83b06decdd0290b522\", headers=headers)\n",
    "print(response.json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962854e4-9195-4160-98a1-91e70e4f98b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the response content from bytes to a string\n",
    "data_str = response.content.decode('utf-8')\n",
    "    \n",
    "# Parse the JSON response into a Python dictionary\n",
    "data = response.json()\n",
    "\n",
    "# Add a missing field with a default value to each record\n",
    "default_value = \"AAPL\"\n",
    "for record in data:\n",
    "    record[\"symbol\"] = default_value\n",
    "\n",
    "# Print the modified data (for debugging)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11098702-01f2-4942-a40b-39ea65fc728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary into a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('AAPL_data.csv', index=False)\n",
    "\n",
    "print(\"Data has been saved to AAPL_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ff342-1ff1-4724-9b3b-114ff85448c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AAPL_data.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001df5b-cae8-4495-b4e2-58cfb936fa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dfea3c-5d6a-40ef-b40e-f9925bf646ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bringing the symbol column from Last position to First\n",
    "\n",
    "# Extract Last Column\n",
    "last_column = df.iloc[:, -1]\n",
    "\n",
    "# Remove Last Column\n",
    "df = df.iloc[:, :-1]\n",
    "\n",
    "# Insert Column at the Beginning\n",
    "df.insert(0, 'symbol', last_column)\n",
    "\n",
    "# Replace 'new_data.csv' with your desired file path\n",
    "df.to_csv('Modified_AAPL_data.csv', index=False)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96a5494-5238-4b5d-9348-cbfe820ae12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769b492-e633-4a9f-9367-d3d10c2ac8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d6c5e-9ed2-48fb-86a6-cfcfea46bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43953f8f-c26c-45fe-8219-fe7b2369dbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caeaed6-4d37-4d9c-b94e-e4b8862bfeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM are sensitive to the scale of the data. So we apply MinMax scaler \n",
    "import numpy as np\n",
    "\n",
    "###Importing MinMaxScaler: The code imports the MinMaxScaler class from the sklearn.preprocessing module, which is used for scaling features to a specified range.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "###Initializing the Scaler: The code initializes an instance of MinMaxScaler named scaler, specifying the desired feature range as (0, 1).\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "###Scaling the Data: The fit_transform() method of the MinMaxScaler object is used to scale the data in df1. The np.array(df1).reshape(-1,1) part converts the data in df1 to a numpy array and reshapes it to have one column. \n",
    "###This is required because MinMaxScaler expects the input to be a 2D array with shape (n_samples, n_features).\n",
    "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f851d5-316d-4230-a1b2-dbbfef2a2516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22747a-3061-45f8-bc4f-3c0703583b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##splitting dataset into train and test split\n",
    "training_size=int(len(df1)*0.65)\n",
    "test_size=len(df1)-training_size\n",
    "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc9d8d-d092-4b47-bd63-7579345ef6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size,test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c08fbf-d4bc-476c-b8fb-ce342ba4aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "\tdataX, dataY = [], []    #This line initializes two empty lists, dataX and dataY, which will be used to store input and output data for the dataset.\n",
    "\tfor i in range(len(dataset)-time_step-1):\n",
    "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + time_step, 0])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed78555d-f282-494a-90a5-9b2e8bc8c1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
    "time_step = 100\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, y_test = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778750e-fd0f-4374-87a2-8d2f484df9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape), print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55986003-8d29-42c1-9ee4-73e2a53bd8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape), print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09927b4-b071-414b-839d-249998ef4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c62c6-d46a-4b1b-aff4-e98785ea4c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the Stacked LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c1004-fb55-4808-a7c8-47eafe781969",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8730b3fe-2a3f-484d-8956-18f69a57bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32114e48-58b7-4db7-87b6-04c9e6456df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=100,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d43602-dda3-4a28-9c4e-50bec242a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6111b0b9-999e-457a-b295-040023fab220",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets Do the prediction and check performance metrics\n",
    "train_predict=model.predict(X_train)\n",
    "test_predict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc604c40-a39c-40ba-96b3-7dd500d1e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Transformback to original form\n",
    "train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf06be90-d669-4447-b82c-4222b761ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate RMSE performance metrics\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "math.sqrt(mean_squared_error(y_train,train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b857ef35-dc2d-42be-b3a7-9afc5a456b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test Data RMSE\n",
    "math.sqrt(mean_squared_error(y_test,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fefed02-785e-4f83-8718-2540d30d7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting \n",
    "# shift train predictions for plotting\n",
    "look_back=100\n",
    "trainPredictPlot = numpy.empty_like(df1)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(df1)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(df1))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded49335-c793-4fc5-80c8-49db734aabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d72a06-2a9f-487a-bcad-4170e3abb601",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_input=test_data[493:].reshape(1,-1)\n",
    "x_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7b302-c7d2-4b36-9680-1b9067995933",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input=list(x_input)\n",
    "temp_input=temp_input[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1407d26-d78f-4643-9ec3-d1340ccdc298",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35283e9-2269-46f4-8cb4-e0c706132654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate prediction for next 90 days\n",
    "from numpy import array\n",
    "\n",
    "lst_output=[]\n",
    "n_steps=300\n",
    "i=0\n",
    "while(i<90):\n",
    "    \n",
    "    if(len(temp_input)>300):\n",
    "        #print(temp_input)\n",
    "        x_input=np.array(temp_input[1:])\n",
    "        print(\"{} day input {}\".format(i,x_input))\n",
    "        x_input=x_input.reshape(1,-1)\n",
    "        x_input = x_input.reshape((1, n_steps, 1))\n",
    "        #print(x_input)\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(\"{} day output {}\".format(i,yhat))\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        temp_input=temp_input[1:]\n",
    "        #print(temp_input)\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1\n",
    "    else:\n",
    "        x_input = x_input.reshape((1, n_steps,1))\n",
    "        yhat = model.predict(x_input, verbose=0)\n",
    "        print(yhat[0])\n",
    "        temp_input.extend(yhat[0].tolist())\n",
    "        print(len(temp_input))\n",
    "        lst_output.extend(yhat.tolist())\n",
    "        i=i+1\n",
    "    \n",
    "\n",
    "print(lst_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17adee-630e-42cc-9402-c7d128c345c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_new=np.arange(1,301)\n",
    "day_pred=np.arange(301,391)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caafe445-8f6b-461d-be86-2f1bdb6ecb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e24abf-0f1f-4e77-8bbd-76f76d03cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b92ab4-9ec0-4356-ab65-0eb472caa094",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(day_new,scaler.inverse_transform(df1[1964:]))\n",
    "plt.plot(day_pred,scaler.inverse_transform(lst_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f0d571-8f7d-456e-9dae-cb343fe06f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df1.tolist()\n",
    "df3.extend(lst_output)\n",
    "plt.plot(df3[1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e40f1-7cab-4f83-9890-70e40079a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=scaler.inverse_transform(df3).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f025c4fb-7051-4775-9fa6-6998d5ed78ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85a1bc-d910-4cd1-9585-4e8db1efc52d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
